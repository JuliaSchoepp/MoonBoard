{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import re\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"problems_2023_01_30/problems MoonBoard Masters 2019 40.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = ['6A+', '6B', '6B+', '6C', '6C+', '7A', '7A+', '7B', '7B+', '7C', '7C+', '8A', '8A+', '8B', '8B+']\n",
    "grade_dict = {grade: i for i, grade in enumerate(grades)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(path: str) -> pd.DataFrame:\n",
    "    with open(path, \"r\") as file:\n",
    "        data = pd.read_json(file)\n",
    "\n",
    "    # Normalize the data\n",
    "    main_df = json_normalize(data['data'])\n",
    "    moves_df = json_normalize(data=data['data'], record_path='moves')\n",
    "\n",
    "    # create dummy variables for the hold, i.e. description column\n",
    "    move_dummies = pd.get_dummies(moves_df.description)\n",
    "    moves_df = pd.concat([moves_df, move_dummies], axis=1)\n",
    "\n",
    "    df = main_df.merge(moves_df, left_on='apiId', right_on='problemId')\n",
    "    \n",
    "    df = df.drop(columns=['moves', 'hasBetaVideo', 'holdsets', 'setbyId', 'userGrade', 'moonBoardConfigurationId',\n",
    "                      'holdsetup.description', 'holdsetup.apiId', 'holdsetup.holdsets', 'description', 'apiId',\n",
    "                      'dateUpdated', 'isMaster'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df: pd.DataFrame, min_repeats=5) -> pd.DataFrame:\n",
    "    # filter out deleted problems\n",
    "    df = df[df.dateDeleted.isnull()]\n",
    "    # filter out problems with no grade\n",
    "    df = df.query(\"grade != 'None'\")\n",
    "    df = df.assign(\n",
    "        # convert grades to numeric\n",
    "        grade=df.grade.map(grade_dict),\n",
    "        # convert date to datetime & extract year\n",
    "        year = pd.to_datetime(df.dateInserted, format='ISO8601').dt.year,\n",
    "    )\n",
    "    df = df.drop(columns=['dateInserted', 'dateDeleted'])\n",
    "    # filter out problems with less than min_repeats repeats\n",
    "    df = df.query(f\"repeats >= {min_repeats}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_problem(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Group by all the columns that are not holds (A1 - K9)\n",
    "    2) For each group (problem), sum over the holds to get dummies for each boulder\n",
    "    3) Mark the start hold and the end hold by as the hold per group where isStart / isEnd is true\n",
    "    \"\"\"\n",
    "    df.set_index('problemId', inplace=True)\n",
    "    # Identify columns matching the pattern: single letter followed by 1 or 2 digits\n",
    "    hold_cols = [col for col in df.columns if re.match(r'^[A-Z]\\d{1,2}$', col)]\n",
    "\n",
    "    # All other columns are non-hold columns\n",
    "    non_hold_cols = [col for col in df.columns if col not in hold_cols]\n",
    "\n",
    "    # Group by non-hold columns and sum over the hold columns\n",
    "    grouped = (df\n",
    "    .groupby('problemId')\n",
    "    [hold_cols]\n",
    "    .sum())\n",
    "\n",
    "    # Add the non-hold columns back to the grouped DataFrame\n",
    "    grouped = (df[non_hold_cols]\n",
    "    .drop(columns=['isStart', 'isEnd'])\n",
    "    .drop_duplicates()).merge(grouped, on='problemId')\n",
    "\n",
    "    # find the hold_col that is true\n",
    "    start_holds = df.query('isStart == True')[hold_cols].idxmax(axis=1)\n",
    "    end_holds = df.query('isEnd == True')[hold_cols].idxmax(axis=1)\n",
    "    start_holds.name = 'startHold'\n",
    "    end_holds.name = 'endHold'\n",
    "\n",
    "    # There can be one or two start holds, so we need to group them\n",
    "    start_holds_grouped = start_holds.groupby(start_holds.index).apply(list)\n",
    "    start_hold_df = pd.DataFrame(start_holds_grouped.tolist(), index=start_holds_grouped.index)\n",
    "    start_hold_df.columns = ['start_hold_1', 'start_hold_2']\n",
    "    start_hold_df['start_hold_2'] = start_hold_df['start_hold_2'].where(pd.notna(start_hold_df['start_hold_2']), np.nan)\n",
    "\n",
    "    # Merge the start and end holds with the grouped DataFrame\n",
    "    grouped = grouped.merge(start_hold_df, left_index=True, right_index=True).merge(end_holds, left_index=True, right_index=True)\n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(path)\n",
    "df = group_by_problem(df)\n",
    "df = prepare_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualize the number of boulders upgraded and downgraded per setter (df.setby)\n",
    "up_down_df = (df\n",
    "    .groupby('setby')\n",
    "    .agg({'upgraded': 'sum', 'downgraded': 'sum', 'name':'count'})\n",
    "    .sort_values('name', ascending=False)\n",
    "    .head(30)\n",
    ")\n",
    "up_down_df = (up_down_df\n",
    "              [(up_down_df.upgraded > 0) | (up_down_df.downgraded > 0)] \n",
    ")\n",
    "up_down_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the average grade per year\n",
    "sns.barplot(x='year', y='grade', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn settings\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Bubble chart\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plotting upgraded bubbles in blue\n",
    "sns.scatterplot(x=up_down_df.index, y=up_down_df['name'], size=up_down_df['upgraded'], sizes=(20, 2000), hue=up_down_df['upgraded'], palette=\"Blues\", legend=\"full\", alpha=0.8)\n",
    "\n",
    "# Plotting downgraded bubbles in red on top of upgraded\n",
    "sns.scatterplot(x=up_down_df.index, y=up_down_df['name'], size=up_down_df['downgraded'], sizes=(20, 2000), hue=up_down_df['downgraded'], palette=\"Reds\", legend=\"full\", alpha=0.8)\n",
    "\n",
    "plt.ylabel('Number of Routes/Problems Set')\n",
    "plt.title('The biggest sandbaggers and softies on the Moonboard')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
